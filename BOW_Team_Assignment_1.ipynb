{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ZBSaJnzf4D2E"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import re\n",
        "import pandas as pd\n",
        "import random\n",
        "from string import ascii_lowercase\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNTa27hDZczm",
        "outputId": "44df4076-d534-4572-aee0-30b813e6a9d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Download NLTK stop words\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Function to clean text: remove punctuation, stop words, and non-textual elements\n",
        "def clean_text(text):\n",
        "    # Remove punctuation\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    # Split into words\n",
        "    words = text.split()\n",
        "    # Remove stop words and non-textual elements\n",
        "    cleaned_words = [word for word in words if word.lower() not in stop_words]\n",
        "    return ' '.join(cleaned_words)\n",
        "\n",
        "def find_start_end(text):\n",
        "    # Find the start and end of the main text\n",
        "    start_pattern = r\"\\*\\*\\* START OF THIS PROJECT GUTENBERG EBOOK .+ \\*\\*\\*\"\n",
        "    end_pattern = r\"\\*\\*\\* END OF THIS PROJECT GUTENBERG EBOOK .+ \\*\\*\\*\"\n",
        "\n",
        "    start_match = re.search(start_pattern, text)\n",
        "    end_match = re.search(end_pattern, text)\n",
        "\n",
        "    start_idx = start_match.end() if start_match else 0\n",
        "    end_idx = end_match.start() if end_match else len(text)\n",
        "\n",
        "    return text[start_idx:end_idx]\n",
        "\n",
        "def process_book(url, label):\n",
        "    # Download the book text from the URL\n",
        "    response = requests.get(url)\n",
        "    response.encoding = 'utf-8'\n",
        "    text = response.text\n",
        "\n",
        "    # Extract the main text between start and end markers\n",
        "    main_text = find_start_end(text)\n",
        "\n",
        "    # Clean the main text\n",
        "    cleaned_text = clean_text(main_text)\n",
        "\n",
        "    # Extract words from the cleaned text\n",
        "    words = cleaned_text.split()\n",
        "\n",
        "    # Split words into partitions of 100 and take 200 random partitions\n",
        "    partitions = [words[i:i + 100] for i in range(0, len(words), 100)]\n",
        "    random_partitions = random.sample(partitions, min(200, len(partitions)))\n",
        "\n",
        "    return [(label, ' '.join(partition)) for partition in random_partitions]\n",
        "\n",
        "# Updated list of Gutenberg book URLs (Same as before, no change needed here)\n",
        "book_urls = [\n",
        "    'https://www.gutenberg.org/files/1342/1342-0.txt',  # Pride and Prejudice by Jane Austen\n",
        "    'https://www.gutenberg.org/files/768/768-0.txt',    # Wuthering Heights by Emily Brontë\n",
        "    'https://www.gutenberg.org/files/1260/1260-0.txt',  # Jane Eyre by Charlotte Brontë\n",
        "    'https://www.gutenberg.org/files/1400/1400-0.txt',  # Great Expectations by Charles Dickens\n",
        "    'https://www.gutenberg.org/files/145/145-0.txt',    # Middlemarch by George Eliot\n",
        "    'https://www.gutenberg.org/files/541/541.txt'       # The Age of Innocence by Edith Wharton\n",
        "]\n",
        "\n",
        "# Generate alphabetic labels based on the number of URLs\n",
        "labels = list(ascii_lowercase)[:len(book_urls)]\n",
        "\n",
        "# Process all books\n",
        "all_partitions = []\n",
        "\n",
        "for url, label in zip(book_urls, labels):\n",
        "    book_partitions = process_book(url, label)\n",
        "    all_partitions.extend(book_partitions)\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(all_partitions, columns=['Label', 'Words'])\n",
        "\n",
        "# Splitting the DataFrame into training (60%), validation (20%), and testing (20%) sets\n",
        "df_train, df_temp = train_test_split(df, test_size=0.4, random_state=42)  # 60% for training, 40% for temp\n",
        "df_validation, df_test = train_test_split(df_temp, test_size=0.5, random_state=42)  # Split temp equally into validation and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KFTqWBu_bsF",
        "outputId": "fc5b3c4c-6c02-4f96-e3bc-e32d7ef516ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validation Results for Naive Bayes:\n",
            "average accuracy: 0.9645833333333332\n",
            "average precision: 0.9675357165892672\n",
            "average recall: 0.9645833333333332\n",
            "average f1: 0.9647937155457205\n",
            "average roc_auc: 0.988922663900935\n",
            "\n",
            "Cross-validation Results for Random Forest:\n",
            "average accuracy: 0.9416666666666667\n",
            "average precision: 0.949014594986054\n",
            "average recall: 0.9416666666666667\n",
            "average f1: 0.9425046529173011\n",
            "average roc_auc: 0.9887668239177996\n",
            "\n",
            "Cross-validation Results for SVM:\n",
            "average accuracy: 0.9135416666666668\n",
            "average precision: 0.9255930767217533\n",
            "average recall: 0.9135416666666668\n",
            "average f1: 0.9151498869528819\n",
            "average roc_auc: 0.9890234476741157\n",
            "\n",
            "Cross-validation Results for k-NN:\n",
            "average accuracy: 0.6979166666666666\n",
            "average precision: 0.7709070551023229\n",
            "average recall: 0.6979166666666666\n",
            "average f1: 0.6843997914835847\n",
            "average roc_auc: 0.9138894657612517\n",
            "\n",
            "Cross-validation Results for SGD:\n",
            "average accuracy: 0.915625\n",
            "average precision: 0.9208002302409355\n",
            "average recall: 0.915625\n",
            "average f1: 0.915260930322618\n",
            "average roc_auc: nan\n",
            "\n",
            "Cross-validation Results for XG-Boost:\n",
            "average accuracy: 0.90625\n",
            "average precision: 0.9172024114345817\n",
            "average recall: 0.90625\n",
            "average f1: 0.9078713693958402\n",
            "average roc_auc: 0.9898127922006041\n",
            "\n",
            "------------\n",
            "\n",
            "Test Set Results for Naive Bayes:\n",
            "average accuracy: 0.9666666666666667\n",
            "average precision: 0.9675161905832358\n",
            "average recall: 0.9666666666666667\n",
            "average f1: 0.9665851922931931\n",
            "average roc_auc: 0.9947611622928093\n",
            "\n",
            "Test Set Results for Random Forest:\n",
            "average accuracy: 0.9416666666666667\n",
            "average precision: 0.949421608265948\n",
            "average recall: 0.9416666666666667\n",
            "average f1: 0.9430115004692473\n",
            "average roc_auc: 0.9928977561288088\n",
            "\n",
            "Test Set Results for SVM:\n",
            "average accuracy: 0.9208333333333333\n",
            "average precision: 0.931865959119497\n",
            "average recall: 0.9208333333333333\n",
            "average f1: 0.9224525666819505\n",
            "average roc_auc: 0.9923679874547547\n",
            "\n",
            "Test Set Results for k-NN:\n",
            "average accuracy: 0.6833333333333333\n",
            "average precision: 0.7622259519749929\n",
            "average recall: 0.6833333333333333\n",
            "average f1: 0.6680555555555557\n",
            "average roc_auc: 0.8889058034609891\n",
            "\n",
            "Test Set Results for SGD:\n",
            "average accuracy: 0.9291666666666667\n",
            "average precision: 0.9296213482911173\n",
            "average recall: 0.9291666666666667\n",
            "average f1: 0.9289505772005773\n",
            "average roc_auc: nan\n",
            "\n",
            "Test Set Results for XG-Boost:\n",
            "average accuracy: 0.9375\n",
            "average precision: 0.9446073717948719\n",
            "average recall: 0.9375\n",
            "average f1: 0.9385988550622846\n",
            "average roc_auc: 0.9946605221008143\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Combine training and validation datasets for cross-validation\n",
        "df_combined = pd.concat([df_train, df_validation])\n",
        "\n",
        "# Feature Extraction with Bag of Words for combined dataset\n",
        "vectorizer = CountVectorizer()\n",
        "X_combined = vectorizer.fit_transform(df_combined['Words'])\n",
        "y_combined = LabelEncoder().fit_transform(df_combined['Label'])\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    \"Naive Bayes\": MultinomialNB(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"SVM\": SVC(probability=True),  # SVM with probability estimates\n",
        "    \"k-NN\": KNeighborsClassifier(),\n",
        "    \"SGD\": SGDClassifier(),\n",
        "    \"XG-Boost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "}\n",
        "\n",
        "# Scoring metrics\n",
        "scoring = {\n",
        "    'average accuracy': make_scorer(accuracy_score),\n",
        "    'average precision': make_scorer(precision_score, average='weighted'),\n",
        "    'average recall': make_scorer(recall_score, average='weighted'),\n",
        "    'average f1': make_scorer(f1_score, average='weighted'),\n",
        "    'average roc_auc': make_scorer(roc_auc_score, needs_proba=True, average='weighted', multi_class='ovr')\n",
        "}\n",
        "\n",
        "# Perform 10-fold cross-validation and evaluate models\n",
        "cv_results = {}\n",
        "kfold = StratifiedKFold(n_splits=10)\n",
        "\n",
        "for name, model in models.items():\n",
        "    cv_scores = cross_validate(model, X_combined, y_combined, cv=kfold, scoring=scoring)\n",
        "    cv_results[name] = cv_scores\n",
        "\n",
        "# Output cross-validation results\n",
        "for model, scores in cv_results.items():\n",
        "    print(f\"Cross-validation Results for {model}:\")\n",
        "    for metric in scoring.keys():\n",
        "        average_score = scores[f'test_{metric}'].mean()\n",
        "        print(f\"{metric}: {average_score}\")\n",
        "    print()\n",
        "\n",
        "print(\"------------\")\n",
        "print()\n",
        "\n",
        "# Feature Extraction for test set\n",
        "X_test = vectorizer.transform(df_test['Words'])\n",
        "y_test = LabelEncoder().fit_transform(df_test['Label'])\n",
        "\n",
        "# Final Evaluation on Test Set\n",
        "test_results = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_combined, y_combined)  # Train on the combined dataset\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_proba = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
        "    test_results[name] = {\n",
        "        'average accuracy': accuracy_score(y_test, y_pred),\n",
        "        'average precision': precision_score(y_test, y_pred, average='weighted'),\n",
        "        'average recall': recall_score(y_test, y_pred, average='weighted'),\n",
        "        'average f1': f1_score(y_test, y_pred, average='weighted'),\n",
        "        'average roc_auc': roc_auc_score(y_test, y_proba, multi_class='ovr', average='weighted') if y_proba is not None else None\n",
        "    }\n",
        "\n",
        "# Output test set results\n",
        "for model, scores in test_results.items():\n",
        "    print(f\"Test Set Results for {model}:\")\n",
        "    for metric, score in scores.items():\n",
        "        if score is not None:\n",
        "            print(f\"{metric}: {score}\")\n",
        "        else:\n",
        "            print(f\"{metric}: nan\")\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
