{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EBFoo5EZQSyV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd5004cf-b7f7-4010-f987-c59cdfffd24b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import re\n",
        "import pandas as pd\n",
        "import random\n",
        "from string import ascii_lowercase\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from urllib.request import urlopen\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XC-gTERQouW"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05lwftILQl4Z",
        "outputId": "e564cea4-7ff1-496b-c980-5a7bc03ea6a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# Download NLTK stop words\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Function to clean text: remove punctuation, stop words, and non-textual elements\n",
        "# def clean_text(text):\n",
        "#     # Remove punctuation\n",
        "#     text = re.sub(r'[^\\w\\s]', '', text)\n",
        "#     # Split into words\n",
        "#     words = text.split()\n",
        "#     # Remove stop words and non-textual elements\n",
        "#     cleaned_words = [word for word in words if word.lower() not in stop_words]\n",
        "#     # strip underscores\n",
        "#     cleaned_words = [word.strip('_') for word in cleaned_words]\n",
        "#     # remove numbers\n",
        "#     cleaned_words = [word for word in cleaned_words if not word.isnumeric()]\n",
        "#     # remove words that start with numbers\n",
        "#     cleaned_words = [word for word in cleaned_words if not word[0].isnumeric()]\n",
        "#     return ' '.join(cleaned_words)\n",
        "\n",
        "# Function to create the partitions\n",
        "def split_into_fixed_partitions(text, partitions=200, words_per_partition=100):\n",
        "    words = text.split()\n",
        "    partitions = [words[i:i + 100] for i in range(0, len(words), 100)]\n",
        "    random_partitions = random.sample(partitions, min(200, len(partitions)))\n",
        "\n",
        "    return random_partitions\n",
        "\n",
        "def find_start_end(text):\n",
        "    # Find the start and end of the main text\n",
        "    start_pattern = r\"\\*\\*\\* START OF THIS PROJECT GUTENBERG EBOOK .+ \\*\\*\\*\"\n",
        "    end_pattern = r\"\\*\\*\\* END OF THIS PROJECT GUTENBERG EBOOK .+ \\*\\*\\*\"\n",
        "\n",
        "    start_match = re.search(start_pattern, text)\n",
        "    end_match = re.search(end_pattern, text)\n",
        "\n",
        "    start_idx = start_match.end() if start_match else 0\n",
        "    end_idx = end_match.start() if end_match else len(text)\n",
        "\n",
        "    return text[start_idx:end_idx]\n",
        "\n",
        "# def process_book(url, label):\n",
        "#     # Download the book text from the URL\n",
        "#     response = requests.get(url)\n",
        "#     response.encoding = 'utf-8'\n",
        "#     text = response.text\n",
        "\n",
        "#     # Extract the main text between start and end markers\n",
        "#     main_text = find_start_end(text)\n",
        "\n",
        "#     # Clean the main text\n",
        "#     cleaned_text = clean_text(main_text)\n",
        "\n",
        "#     # Extract words from the cleaned text\n",
        "#     words = cleaned_text.split()\n",
        "\n",
        "#     # Split words into partitions of 100 and take 200 random partitions\n",
        "#     partitions = [words[i:i + 100] for i in range(0, len(words), 100)]\n",
        "#     random_partitions = random.sample(partitions, min(200, len(partitions)))\n",
        "\n",
        "#     return [(label, ' '.join(partition)) for partition in random_partitions]\n",
        "\n",
        "def process_book(url):\n",
        "  raw = urlopen(url).read()\n",
        "\n",
        "  # convert raw format to string and fetch author name of the book\n",
        "  string_txt = str(raw)\n",
        "  author_name_match = re.search(r'Author:?[\\w\\s;:,\\'\\\"]+',string_txt)\n",
        "  tokens = word_tokenize(string_txt)\n",
        "  author_name = author_name_match.group(0)[7:len(author_name_match.group(0))]\n",
        "\n",
        "  #Remove stop words from the text\n",
        "  stwrd = stopwords.words('english')\n",
        "  cleaned_string = [word for word in tokens if word.lower() not in stwrd and word.isalpha()]\n",
        "  cleaned_string = ' '.join(cleaned_string)\n",
        "\n",
        "  #removing special characters and escape sequences\n",
        "  cleaned_string = re.sub(r'\\\\[^,:;]+|[^\\x20-\\x7E]+','',cleaned_string)\n",
        "  new_string = find_start_end(cleaned_string)\n",
        "\n",
        "  #Split the text into partitions\n",
        "  partitions = split_into_fixed_partitions(cleaned_string, partitions=200, words_per_partition=100)\n",
        "  partitions = [{\"Words\" : ' '.join(part), \"Label\" : author_name} for part in partitions]\n",
        "  return partitions\n",
        "\n",
        "# Updated list of Gutenberg book URLs (Same as before, no change needed here)\n",
        "# book_urls = [\n",
        "#     'https://www.gutenberg.org/files/1342/1342-0.txt',  # Pride and Prejudice by Jane Austen\n",
        "#     'https://www.gutenberg.org/files/768/768-0.txt',    # Wuthering Heights by Emily Brontë\n",
        "#     'https://www.gutenberg.org/files/1260/1260-0.txt',  # Jane Eyre by Charlotte Brontë\n",
        "#     'https://www.gutenberg.org/files/1400/1400-0.txt',  # Great Expectations by Charles Dickens\n",
        "#     'https://www.gutenberg.org/files/145/145-0.txt',    # Middlemarch by George Eliot\n",
        "#     'https://www.gutenberg.org/files/541/541.txt'       # The Age of Innocence by Edith Wharton\n",
        "# ]\n",
        "\n",
        "# book_authors = [\"Jane Austen\", \"Emily Bronte\", \"Charlotte Bronte\", \"Charles Dickens\",  \"George Eliot\", \"Edith Wharton\"]\n",
        "book_urls = [\n",
        "    'https://www.gutenberg.org/cache/epub/1342/pg1342.txt',  # Pride and Prejudice by Jane Austen\n",
        "    'https://www.gutenberg.org/cache/epub/768/pg768.txt',    # Wuthering Heights by Emily Brontë\n",
        "    'https://www.gutenberg.org/cache/epub/1260/pg1260.txt',    # Jane Eyre: An Autobiography by Charlotte Brontë\n",
        "    'https://www.gutenberg.org/cache/epub/1400/pg1400.txt',    # Great Expectations Charles Dickens\n",
        "    'https://www.gutenberg.org/cache/epub/145/pg145.txt',      # Middlemarch by George Eliot\n",
        "    'https://www.gutenberg.org/cache/epub/541/pg541.txt'       # The Age of Innocence by Edith Wharton\n",
        "]\n",
        "\n",
        "\n",
        "# Process all books\n",
        "all_partitions = []\n",
        "\n",
        "# for url, label in zip(book_urls, book_authors):\n",
        "for url in book_urls:\n",
        "    book_partitions = process_book(url)\n",
        "    all_partitions.extend(book_partitions)\n",
        "\n",
        "# Convert to DataFrame\n",
        "partition_df = pd.DataFrame(all_partitions)\n",
        "\n",
        "# Serialize DataFrame to CSV\n",
        "partition_df.to_csv('book_partitions_cleaned.csv', index=False)\n",
        "\n",
        "partition_df = shuffle(partition_df, random_state=69)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "partition_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SwjrQakO-SyD",
        "outputId": "9c0197d6-13f8-4469-e421-2feb54bbfb82"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  Words             Label\n",
              "543   seated proud grace piano snowy robes queenly a...   Charlotte Bront\n",
              "1149  wife mean asked indistinct still looked transp...     Edith Wharton\n",
              "653   would something days formed plan outline besto...   Charles Dickens\n",
              "934   said wished marry man loved marry Lydgate seve...      George Eliot\n",
              "668   one called said voice darkness floor want top ...   Charles Dickens"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c91d0ed8-c210-4616-9937-cd34ae2d4806\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Words</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>543</th>\n",
              "      <td>seated proud grace piano snowy robes queenly a...</td>\n",
              "      <td>Charlotte Bront</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1149</th>\n",
              "      <td>wife mean asked indistinct still looked transp...</td>\n",
              "      <td>Edith Wharton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>653</th>\n",
              "      <td>would something days formed plan outline besto...</td>\n",
              "      <td>Charles Dickens</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>934</th>\n",
              "      <td>said wished marry man loved marry Lydgate seve...</td>\n",
              "      <td>George Eliot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>668</th>\n",
              "      <td>one called said voice darkness floor want top ...</td>\n",
              "      <td>Charles Dickens</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c91d0ed8-c210-4616-9937-cd34ae2d4806')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c91d0ed8-c210-4616-9937-cd34ae2d4806 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c91d0ed8-c210-4616-9937-cd34ae2d4806');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f324568f-b140-40ce-8033-6fbac4eb0518\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f324568f-b140-40ce-8033-6fbac4eb0518')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f324568f-b140-40ce-8033-6fbac4eb0518 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BdkiMXMR-DS"
      },
      "source": [
        "# Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Xlj5GVDlR9x6"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "bow_vectorizer = CountVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AqiYHxTwRtp3"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        ")\n",
        "from sklearn.multiclass import OneVsRestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VEPfgQ_BSsTe"
      },
      "outputs": [],
      "source": [
        "model_objs = [\n",
        "    OneVsRestClassifier(SVC(kernel=\"rbf\")),\n",
        "    RandomForestClassifier(),\n",
        "    OneVsRestClassifier(GaussianNB()),\n",
        "    KNeighborsClassifier(),\n",
        "    OneVsRestClassifier(SGDClassifier()),\n",
        "    DecisionTreeClassifier(),\n",
        "    OneVsRestClassifier(AdaBoostClassifier()),\n",
        "    OneVsRestClassifier(XGBClassifier(random_state=69))\n",
        "    ]\n",
        "\n",
        "\n",
        "model_names = [\n",
        "    \"Gaussian SVC\",\n",
        "    \"RandomForestClassifier\",\n",
        "    \"Naive Bayes\",\n",
        "    \"KNeighborsClassifier\",\n",
        "    \"SGDClassifier\",\n",
        "    \"DecisionTreeClassifier\",\n",
        "    \"AdaBoostClassifier\",\n",
        "    \"XGBClassifier\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "partition_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MrsKAGEKT0j",
        "outputId": "75c2b1bc-23a0-46ff-f83d-d444d2c4dc61"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOJnVMoiS45W"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=69)\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Lists to store metric values for each model\n",
        "accuracy_list = []\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "f1_list = []\n",
        "roc_auc_list = []\n",
        "\n",
        "for m_obj, m_name in zip(model_objs, model_names):\n",
        "  acc_sum = 0\n",
        "  precision_sum = 0\n",
        "  recall_sum = 0\n",
        "  f1_sum = 0\n",
        "  roc_auc_sum = 0\n",
        "  for train_index,test_index in kf.split(partition_df):\n",
        "    train_data = partition_df.iloc[train_index]\n",
        "    test_data = partition_df.iloc[test_index]\n",
        "    X_train = train_data.drop(['Label'], axis=1)\n",
        "    y_train = train_data['Label']\n",
        "    X_test = test_data.drop(['Label'], axis=1)\n",
        "    y_test = test_data['Label']\n",
        "    # One-hot encoding for the label\n",
        "    y_train_onehot = onehot_encoder.fit_transform(train_data[['Label']])\n",
        "    y_test_onehot = onehot_encoder.transform(test_data[['Label']])\n",
        "\n",
        "    y_train_df = pd.DataFrame(y_train_onehot, columns=onehot_encoder.get_feature_names_out(['Label']))\n",
        "    y_test_df = pd.DataFrame(y_test_onehot, columns=onehot_encoder.get_feature_names_out(['Label']))\n",
        "\n",
        "    X_train_bow = bow_vectorizer.fit_transform(X_train['Words'])\n",
        "    X_test_bow = bow_vectorizer.transform(X_test['Words'])\n",
        "    X_train_bow = pd.DataFrame(X_train_bow.toarray(), columns=bow_vectorizer.get_feature_names_out())\n",
        "    X_test_bow = pd.DataFrame(X_test_bow.toarray(), columns=bow_vectorizer.get_feature_names_out())\n",
        "\n",
        "    m_obj.fit(X_train_bow, y_train_df),\n",
        "    y_pred = m_obj.predict(X_test_bow)\n",
        "    acc = accuracy_score(y_pred, y_test_df)\n",
        "    precision = precision_score(y_pred, y_test_df, average='macro')\n",
        "    recall = recall_score(y_pred, y_test_df, average='macro')\n",
        "    f1 = f1_score(y_pred, y_test_df, average='macro')\n",
        "    roc_auc = roc_auc_score(y_test_df, y_pred,  average='macro')\n",
        "\n",
        "    acc_sum+=acc\n",
        "    precision_sum += precision\n",
        "    recall_sum += recall\n",
        "    f1_sum += f1\n",
        "    roc_auc_sum += roc_auc\n",
        "\n",
        "  # Calculate average metric values for the model\n",
        "  avg_acc = acc_sum / 10\n",
        "  avg_precision = precision_sum / 10\n",
        "  avg_recall = recall_sum / 10\n",
        "  avg_f1 = f1_sum / 10\n",
        "  avg_roc_auc = roc_auc_sum / 10\n",
        "\n",
        "  # Append the average metric values to the respective lists\n",
        "  accuracy_list.append(avg_acc)\n",
        "  precision_list.append(avg_precision)\n",
        "  recall_list.append(avg_recall)\n",
        "  f1_list.append(avg_f1)\n",
        "  roc_auc_list.append(avg_roc_auc)\n",
        "\n",
        "\n",
        "  print(\"MODEL: {}\".format(m_name))\n",
        "  print(\"Average Accuracy: {}\".format(acc_sum/10))\n",
        "  print(\"Average Precision: {}\".format(precision_sum/10))\n",
        "  print(\"Average Recall: {}\".format(recall_sum/10))\n",
        "  print(\"Average F1: {}\".format(f1_sum/10))\n",
        "  print(\"Average ROC AUC: {}\".format(roc_auc_sum/10))\n",
        "  print()\n",
        "\n",
        "\n",
        "# Plotting the graph\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1', 'ROC AUC']\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.subplots_adjust(bottom=0.3)\n",
        "\n",
        "for i, metric_list in enumerate([accuracy_list, precision_list, recall_list, f1_list, roc_auc_list]):\n",
        "    plt.plot(model_names, metric_list, label=metrics[i])\n",
        "\n",
        "\n",
        "plt.title('Model Performance Comparison (Bag of Words)')\n",
        "plt.xlabel('Models')\n",
        "\n",
        "# Rotate model names vertically\n",
        "plt.xticks(rotation=90, ha='center')\n",
        "\n",
        "plt.ylabel('Metric Value')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnxZbrPaThR_"
      },
      "source": [
        "# TF IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wy37iDXNr60x"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize the TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9Sv_Ko5ClfC"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=69)\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Lists to store metric values for each model\n",
        "accuracy_list = []\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "f1_list = []\n",
        "roc_auc_list = []\n",
        "\n",
        "\n",
        "for m_obj, m_name in zip(model_objs, model_names):\n",
        "  acc_sum = 0\n",
        "  precision_sum = 0\n",
        "  recall_sum = 0\n",
        "  f1_sum = 0\n",
        "  roc_auc_sum = 0\n",
        "  for train_index,test_index in kf.split(partition_df):\n",
        "    train_data = partition_df.iloc[train_index]\n",
        "    test_data = partition_df.iloc[test_index]\n",
        "    X_train = train_data.drop(['Label'], axis=1)\n",
        "    y_train = train_data['Label']\n",
        "    X_test = test_data.drop(['Label'], axis=1)\n",
        "    y_test = test_data['Label']\n",
        "    # One-hot encoding for the label\n",
        "    y_train_onehot = onehot_encoder.fit_transform(train_data[['Label']])\n",
        "    y_test_onehot = onehot_encoder.transform(test_data[['Label']])\n",
        "\n",
        "    y_train_df = pd.DataFrame(y_train_onehot, columns=onehot_encoder.get_feature_names_out(['Label']))\n",
        "    y_test_df = pd.DataFrame(y_test_onehot, columns=onehot_encoder.get_feature_names_out(['Label']))\n",
        "\n",
        "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['Words'])\n",
        "    X_test_tfidf = tfidf_vectorizer.transform(X_test['Words'])\n",
        "    X_train_tfidf = pd.DataFrame(X_train_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
        "    X_test_tfidf = pd.DataFrame(X_test_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
        "\n",
        "    m_obj.fit(X_train_tfidf, y_train_df),\n",
        "    y_pred = m_obj.predict(X_test_tfidf)\n",
        "    acc = accuracy_score(y_pred, y_test_df)\n",
        "    precision = precision_score(y_pred, y_test_df, average='macro')\n",
        "    recall = recall_score(y_pred, y_test_df, average='macro')\n",
        "    f1 = f1_score(y_pred, y_test_df, average='macro')\n",
        "    roc_auc = roc_auc_score(y_test_df, y_pred, average='macro')\n",
        "\n",
        "    acc_sum+=acc\n",
        "    precision_sum += precision\n",
        "    recall_sum += recall\n",
        "    f1_sum += f1\n",
        "    roc_auc_sum += roc_auc\n",
        "\n",
        "  # Calculate average metric values for the model\n",
        "  avg_acc = acc_sum / 10\n",
        "  avg_precision = precision_sum / 10\n",
        "  avg_recall = recall_sum / 10\n",
        "  avg_f1 = f1_sum / 10\n",
        "  avg_roc_auc = roc_auc_sum / 10\n",
        "\n",
        "  # Append the average metric values to the respective lists\n",
        "  accuracy_list.append(avg_acc)\n",
        "  precision_list.append(avg_precision)\n",
        "  recall_list.append(avg_recall)\n",
        "  f1_list.append(avg_f1)\n",
        "  roc_auc_list.append(avg_roc_auc)\n",
        "\n",
        "  print(\"MODEL: {}\".format(m_name))\n",
        "  print(\"Average Accuracy: {}\".format(acc_sum/10))\n",
        "  print(\"Average Precision: {}\".format(precision_sum/10))\n",
        "  print(\"Average Recall: {}\".format(recall_sum/10))\n",
        "  print(\"Average F1: {}\".format(f1_sum/10))\n",
        "  print(\"Average ROC AUC: {}\".format(roc_auc_sum/10))\n",
        "  print()\n",
        "\n",
        "  # Plotting the graph\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1', 'ROC AUC']\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.subplots_adjust(bottom=0.3)\n",
        "\n",
        "for i, metric_list in enumerate([accuracy_list, precision_list, recall_list, f1_list, roc_auc_list]):\n",
        "    plt.plot(model_names, metric_list, label=metrics[i])\n",
        "\n",
        "\n",
        "plt.title('Model Performance Comparison (TF IDF)')\n",
        "plt.xlabel('Models')\n",
        "\n",
        "# Rotate model names vertically\n",
        "plt.xticks(rotation=90, ha='center')\n",
        "\n",
        "plt.ylabel('Metric Value')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8Ck1Dx5UXTk"
      },
      "source": [
        "# Word embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YD8i6A3DUWqY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "glove_file_path= 'glove.6B.50d.txt'\n",
        "\n",
        "# Function to load GloVe embeddings into a dictionary\n",
        "def load_glove_embeddings(file_path):\n",
        "    embeddings = {}\n",
        "    with open(file_path, encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings[word] = vector\n",
        "    return embeddings\n",
        "\n",
        "# Load GloVe embeddings into the dictionary\n",
        "glove_embeddings = load_glove_embeddings(glove_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isMZusL5TxX0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Assuming you have defined 'model' and 'names' somewhere in your code\n",
        "\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=69)\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Lists to store metric values for each model\n",
        "accuracy_list = []\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "f1_list = []\n",
        "roc_auc_list = []\n",
        "\n",
        "for m_obj, m_name in zip(model_objs, model_names):\n",
        "    acc_sum = 0\n",
        "    precision_sum = 0\n",
        "    recall_sum = 0\n",
        "    f1_sum = 0\n",
        "    roc_auc_sum = 0\n",
        "\n",
        "    for train_index, test_index in kf.split(partition_df):\n",
        "        train_data = partition_df.iloc[train_index]\n",
        "        test_data = partition_df.iloc[test_index]\n",
        "        X_train = train_data['Words']\n",
        "        y_train = train_data['Label']\n",
        "        X_test = test_data['Words']\n",
        "        y_test = train_data['Label']\n",
        "\n",
        "        # Create document embeddings using GloVe\n",
        "        X_train_glove = np.array([np.mean([glove_embeddings.get(word, np.zeros(50)) for word in sentence.split()], axis=0) for sentence in X_train])\n",
        "        X_test_glove = np.array([np.mean([glove_embeddings.get(word, np.zeros(50)) for word in sentence.split()], axis=0) for sentence in X_test])\n",
        "\n",
        "        # One-hot encoding for the label\n",
        "        y_train_onehot = onehot_encoder.fit_transform(train_data[['Label']])\n",
        "        y_test_onehot = onehot_encoder.transform(test_data[['Label']])\n",
        "        y_train_df = pd.DataFrame(y_train_onehot, columns=onehot_encoder.get_feature_names_out(['Label']))\n",
        "        y_test_df = pd.DataFrame(y_test_onehot, columns=onehot_encoder.get_feature_names_out(['Label']))\n",
        "\n",
        "        #Model Training and Prediction\n",
        "        m_obj.fit(X_train_glove, y_train_df)\n",
        "        y_pred = m_obj.predict(X_test_glove)\n",
        "\n",
        "        # Compute Evaluation Metrics\n",
        "        acc = accuracy_score(y_pred, y_test_df)\n",
        "        precision = precision_score(y_pred, y_test_df, average='macro')\n",
        "        recall = recall_score(y_pred, y_test_df, average='macro')\n",
        "        f1 = f1_score(y_pred, y_test_df, average='macro')\n",
        "        roc_auc = roc_auc_score(y_test_df, y_pred, average='macro')\n",
        "\n",
        "        acc_sum += acc\n",
        "        precision_sum += precision\n",
        "        recall_sum += recall\n",
        "        f1_sum += f1\n",
        "        roc_auc_sum += roc_auc\n",
        "\n",
        "    # Calculate average metric values for the model\n",
        "    avg_acc = acc_sum / 10\n",
        "    avg_precision = precision_sum / 10\n",
        "    avg_recall = recall_sum / 10\n",
        "    avg_f1 = f1_sum / 10\n",
        "    avg_roc_auc = roc_auc_sum / 10\n",
        "\n",
        "    # Append the average metric values to the respective lists\n",
        "    accuracy_list.append(avg_acc)\n",
        "    precision_list.append(avg_precision)\n",
        "    recall_list.append(avg_recall)\n",
        "    f1_list.append(avg_f1)\n",
        "    roc_auc_list.append(avg_roc_auc)\n",
        "\n",
        "    print(\"MODEL: {}\".format(m_name))\n",
        "    print(\"Average Accuracy: {}\".format(avg_acc))\n",
        "    print(\"Average Precision: {}\".format(avg_precision))\n",
        "    print(\"Average Recall: {}\".format(avg_recall))\n",
        "    print(\"Average F1: {}\".format(avg_f1))\n",
        "    print(\"Average ROC AUC: {}\".format(avg_roc_auc))\n",
        "    print()\n",
        "\n",
        "# Plotting the graph\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1', 'ROC AUC']\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.subplots_adjust(bottom=0.3)\n",
        "\n",
        "for i, metric_list in enumerate([accuracy_list, precision_list, recall_list, f1_list, roc_auc_list]):\n",
        "    plt.plot(model_names, metric_list, label=metrics[i])\n",
        "\n",
        "\n",
        "plt.title('Model Performance Comparison')\n",
        "plt.xlabel('Models')\n",
        "\n",
        "# Rotate model names vertically\n",
        "plt.xticks(rotation=90, ha='center')\n",
        "\n",
        "plt.ylabel('Metric Value')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9Bko1C09nrh"
      },
      "source": [
        "# N-Gram\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOVkt3cd9nri"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=69)\n",
        "onehot_encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
        "\n",
        "# Lists to store metric values for each model\n",
        "accuracy_list = []\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "f1_list = []\n",
        "roc_auc_list = []\n",
        "\n",
        "for m_obj, m_name in zip(model_objs, model_names):\n",
        "  acc_sum = 0\n",
        "  precision_sum = 0\n",
        "  recall_sum = 0\n",
        "  f1_sum = 0\n",
        "  roc_auc_sum = 0\n",
        "  for train_index,test_index in kf.split(partition_df):\n",
        "    train_set, test_set = partition_df.iloc[train_index], partition_df.iloc[test_index]\n",
        "\n",
        "    X_train = train_set.drop(['Label'], axis=1)\n",
        "    y_train = train_set['Label']\n",
        "    X_test = test_set.drop(['Label'], axis=1)\n",
        "    y_test = test_set['Label']\n",
        "\n",
        "    min_n, max_n = 1, 2  # Example: Trying n-grams from 1 to 2\n",
        "    ngram_range_values = [(i, j) for i in range(min_n, max_n + 1) for j in range(i, max_n + 1)]\n",
        "\n",
        "    # One-hot encoding for the label\n",
        "    y_train_onehot = onehot_encoder.fit_transform(train_set[['Label']])\n",
        "    y_test_onehot = onehot_encoder.transform(test_set[['Label']])\n",
        "\n",
        "\n",
        "    y_train_df = pd.DataFrame(y_train_onehot, columns=onehot_encoder.get_feature_names_out(['Label']))\n",
        "    y_test_df = pd.DataFrame(y_test_onehot, columns=onehot_encoder.get_feature_names_out(['Label']))\n",
        "\n",
        "    max_acc,max_precision,max_recall,max_f1,max_roc_auc = [-1,-1,-1,-1,-1]\n",
        "\n",
        "    for ngrams in ngram_range_values:\n",
        "      vec = CountVectorizer(ngram_range = ngrams)\n",
        "      X_train_vec = vec.fit_transform(X_train['Words'])\n",
        "      X_train_vec = pd.DataFrame(X_train_vec.toarray(), columns=vec.get_feature_names_out())\n",
        "      X_test_vec = vec.transform(X_test['Words'])\n",
        "      X_test_vec = pd.DataFrame(X_test_vec.toarray(), columns=vec.get_feature_names_out())\n",
        "      m_obj.fit(X_train_vec,y_train_df)\n",
        "      y_pred = m_obj.predict(X_test_vec)\n",
        "      acc = accuracy_score(y_pred, y_test_df)\n",
        "      precision = precision_score(y_pred, y_test_df, average='macro')\n",
        "      recall = recall_score(y_pred, y_test_df, average='macro')\n",
        "      f1 = f1_score(y_test_df, y_pred, average='macro')\n",
        "      roc_auc = roc_auc_score(y_test_df, y_pred, average='macro')\n",
        "\n",
        "      max_acc = max(max_acc,acc)\n",
        "      max_precision = max(max_precision,precision)\n",
        "      max_recall = max(max_recall,recall)\n",
        "      max_f1 = max(max_f1,f1)\n",
        "      max_roc_auc = max(max_roc_auc,roc_auc)\n",
        "\n",
        "    acc_sum+=max_acc\n",
        "    precision_sum += max_precision\n",
        "    recall_sum += max_recall\n",
        "    f1_sum += max_f1\n",
        "    roc_auc_sum += max_roc_auc\n",
        "\n",
        "  # Append the average metric values to the respective lists\n",
        "  accuracy_list.append(acc_sum/10)\n",
        "  precision_list.append(precision_sum/10)\n",
        "  recall_list.append(recall_sum/10)\n",
        "  f1_list.append(f1_sum/10)\n",
        "  roc_auc_list.append(roc_auc_sum/10)\n",
        "\n",
        "  print(\"MODEL: {}\".format(m_name))\n",
        "  print(\"Average Accuracy: {}\".format(acc_sum/10))\n",
        "  print(\"Average Precision: {}\".format(precision_sum/10))\n",
        "  print(\"Average Recall: {}\".format(recall_sum/10))\n",
        "  print(\"Average F1: {}\".format(f1_sum/10))\n",
        "  print(\"Average ROC AUC: {}\".format(roc_auc_sum/10))\n",
        "  print()\n",
        "\n",
        "# Plotting the graph\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1', 'ROC AUC']\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.subplots_adjust(bottom=0.3)\n",
        "\n",
        "for i, metric_list in enumerate([accuracy_list, precision_list, recall_list, f1_list, roc_auc_list]):\n",
        "    plt.plot(model_names, metric_list, label=metrics[i])\n",
        "\n",
        "\n",
        "plt.title('Model Performance Comparison')\n",
        "plt.xlabel('Models')\n",
        "\n",
        "# Rotate model names vertically\n",
        "plt.xticks(rotation=90, ha='center')\n",
        "\n",
        "plt.ylabel('Metric Value')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QW9DHmQJU2p"
      },
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBUu9VzuJ1qQ"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avGfSR3YPIPV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8t0dCypmJex7"
      },
      "outputs": [],
      "source": [
        "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1'\n",
        "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRBCF9JwI8be"
      },
      "outputs": [],
      "source": [
        "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1O4ncrD6JJz8"
      },
      "outputs": [],
      "source": [
        "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awzRkcK6JWjC"
      },
      "outputs": [],
      "source": [
        "text_test = ['this is such an amazing movie!']\n",
        "text_preprocessed = bert_preprocess_model(text_test)\n",
        "\n",
        "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
        "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
        "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
        "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
        "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVrP2qRRJOwJ"
      },
      "outputs": [],
      "source": [
        "bert_results = bert_model(text_preprocessed)\n",
        "\n",
        "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
        "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
        "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
        "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
        "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9leNQPjJS-z"
      },
      "outputs": [],
      "source": [
        "def build_classifier_model():\n",
        "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "  encoder_inputs = preprocessing_layer(text_input)\n",
        "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "  outputs = encoder(encoder_inputs)\n",
        "  net = outputs['pooled_output']\n",
        "  net = tf.keras.layers.Dense(128, activation='relu', name='hidden_1')(net)\n",
        "  net = tf.keras.layers.Dropout(0.3)(net)\n",
        "  net = tf.keras.layers.Dense(6, activation='softmax', name='classifier')(net)\n",
        "  return tf.keras.Model(text_input, net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4eyTvI-JcsH"
      },
      "outputs": [],
      "source": [
        "classifier_model = build_classifier_model()\n",
        "bert_raw_result = classifier_model(tf.constant(text_test))\n",
        "print(bert_raw_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bl2MmOwfMIwQ"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(classifier_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEtQxDK2MPob"
      },
      "outputs": [],
      "source": [
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "metrics = tf.metrics.CategoricalAccuracy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHJFuUkWNP3O"
      },
      "outputs": [],
      "source": [
        "X = partition_df.drop(['Label'], axis=1)\n",
        "y = partition_df['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nT50RFWiNXoe"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import warnings\n",
        "import numpy as np\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "y_train_onehot = onehot_encoder.fit_transform(np.array(y_train).reshape(-1,1))\n",
        "y_test_onehot = onehot_encoder.transform(np.array(y_test).reshape(-1,1))\n",
        "\n",
        "y_train_df = pd.DataFrame(y_train_onehot, columns=onehot_encoder.get_feature_names_out(['Label']))\n",
        "y_test_df = pd.DataFrame(y_test_onehot, columns=onehot_encoder.get_feature_names_out(['Label']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChqYMFCcQD9z"
      },
      "outputs": [],
      "source": [
        "y_train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQCQlwweMjPd"
      },
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "optimizer = tf.keras.optimizers.Adam(0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBiomcltMmFC"
      },
      "outputs": [],
      "source": [
        "classifier_model.compile(optimizer=optimizer,\n",
        "                         loss=loss,\n",
        "                         metrics=metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uzdbEyTVNdw"
      },
      "outputs": [],
      "source": [
        "classifier_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3-KEz34Ny7U"
      },
      "outputs": [],
      "source": [
        "history = classifier_model.fit(X_train,y_train_df, batch_size=128, epochs=epochs, validation_data=(X_test, y_test_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZ855V5NZNfv"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jq6xrMG_Oznt"
      },
      "outputs": [],
      "source": [
        "y_pred = to_categorical(np.argmax(classifier_model.predict(X_test), axis=-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AxmU_-zYOx5"
      },
      "outputs": [],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iihke22-Xmgk"
      },
      "outputs": [],
      "source": [
        "acc = accuracy_score(y_pred, y_test_df)\n",
        "precision = precision_score(y_pred, y_test_onehot, average='macro')\n",
        "recall = recall_score(y_pred, y_test_onehot, average='macro')\n",
        "f1 = f1_score(y_pred, y_test_onehot, average='macro')\n",
        "roc_auc = roc_auc_score(y_test_onehot, y_pred, average='macro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krTXYdBWXwvw"
      },
      "outputs": [],
      "source": [
        "print(\"Average Accuracy: {}\".format(acc))\n",
        "print(\"Average Precision: {}\".format(precision))\n",
        "print(\"Average Recall: {}\".format(recall))\n",
        "print(\"Average F1: {}\".format(f1))\n",
        "print(\"Average ROC AUC: {}\".format(roc_auc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekY3AWGfZbjr"
      },
      "outputs": [],
      "source": [
        "classifier_model.save('BERT_classifier.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIcNp-j_Z2dF"
      },
      "source": [
        "# Error analysis: BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqS2cns2Z3m_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}