{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import re\n",
        "import pandas as pd\n",
        "import random\n",
        "from string import ascii_lowercase\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "ZBSaJnzf4D2E"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK stop words\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Function to clean text: remove punctuation, stop words, and non-textual elements\n",
        "def clean_text(text):\n",
        "    # Remove punctuation\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    # Split into words\n",
        "    words = text.split()\n",
        "    # Remove stop words and non-textual elements\n",
        "    cleaned_words = [word for word in words if word.lower() not in stop_words]\n",
        "    # strip underscores\n",
        "    cleaned_words = [word.strip('_') for word in cleaned_words]\n",
        "    # remove numbers\n",
        "    cleaned_words = [word for word in cleaned_words if not word.isnumeric()]\n",
        "    return ' '.join(cleaned_words)\n",
        "\n",
        "def find_start_end(text):\n",
        "    # Find the start and end of the main text\n",
        "    start_pattern = r\"\\*\\*\\* START OF THIS PROJECT GUTENBERG EBOOK .+ \\*\\*\\*\"\n",
        "    end_pattern = r\"\\*\\*\\* END OF THIS PROJECT GUTENBERG EBOOK .+ \\*\\*\\*\"\n",
        "\n",
        "    start_match = re.search(start_pattern, text)\n",
        "    end_match = re.search(end_pattern, text)\n",
        "\n",
        "    start_idx = start_match.end() if start_match else 0\n",
        "    end_idx = end_match.start() if end_match else len(text)\n",
        "\n",
        "    return text[start_idx:end_idx]\n",
        "\n",
        "def process_book(url, label):\n",
        "    # Download the book text from the URL\n",
        "    response = requests.get(url)\n",
        "    response.encoding = 'utf-8'\n",
        "    text = response.text\n",
        "\n",
        "    # Extract the main text between start and end markers\n",
        "    main_text = find_start_end(text)\n",
        "\n",
        "    # Clean the main text\n",
        "    cleaned_text = clean_text(main_text)\n",
        "\n",
        "    # Extract words from the cleaned text\n",
        "    words = cleaned_text.split()\n",
        "\n",
        "    # Split words into partitions of 100 and take 200 random partitions\n",
        "    partitions = [words[i:i + 100] for i in range(0, len(words), 100)]\n",
        "    random_partitions = random.sample(partitions, min(200, len(partitions)))\n",
        "\n",
        "    return [(label, ' '.join(partition)) for partition in random_partitions]\n",
        "\n",
        "# Updated list of Gutenberg book URLs (Same as before, no change needed here)\n",
        "book_urls = [\n",
        "    'https://www.gutenberg.org/files/1342/1342-0.txt',  # Pride and Prejudice by Jane Austen\n",
        "    'https://www.gutenberg.org/files/768/768-0.txt',    # Wuthering Heights by Emily Brontë\n",
        "    'https://www.gutenberg.org/files/1260/1260-0.txt',  # Jane Eyre by Charlotte Brontë\n",
        "    'https://www.gutenberg.org/files/1400/1400-0.txt',  # Great Expectations by Charles Dickens\n",
        "    'https://www.gutenberg.org/files/145/145-0.txt',    # Middlemarch by George Eliot\n",
        "    'https://www.gutenberg.org/files/541/541.txt'       # The Age of Innocence by Edith Wharton\n",
        "]\n",
        "\n",
        "book_authors = [\"Jane Austen\", \"Emily Bronte\", \"Charlotte Bronte\", \"Charles Dickens\",  \"George Eliot\", \"Edith Wharton\"]\n",
        "\n",
        "\n",
        "# Process all books\n",
        "all_partitions = []\n",
        "\n",
        "for url, label in zip(book_urls, book_authors):\n",
        "    book_partitions = process_book(url, label)\n",
        "    all_partitions.extend(book_partitions)\n",
        "\n",
        "# Convert to DataFrame\n",
        "partition_df = pd.DataFrame(all_partitions, columns=['Label', 'Words']).sample(frac=1)\n",
        "\n",
        "# Serialize DataFrame to CSV\n",
        "partition_df.to_csv('book_partitions_cleaned.csv', index=False)\n"
      ],
      "metadata": {
        "id": "RNTa27hDZczm",
        "outputId": "2b630cff-d45e-4606-e5e8-19836b61259d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize the TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()"
      ],
      "metadata": {
        "id": "wy37iDXNr60x"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        ")\n",
        "from sklearn.multiclass import OneVsRestClassifier"
      ],
      "metadata": {
        "id": "Jr5aTIB3AioG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_objs = [\n",
        "    OneVsRestClassifier(SVC(kernel=\"rbf\")),\n",
        "    RandomForestClassifier(),\n",
        "    OneVsRestClassifier(GaussianNB()),\n",
        "    KNeighborsClassifier(),\n",
        "    OneVsRestClassifier(SGDClassifier()),\n",
        "    DecisionTreeClassifier(),\n",
        "    OneVsRestClassifier(AdaBoostClassifier()),\n",
        "    OneVsRestClassifier(XGBClassifier(random_state=69))\n",
        "    ]\n",
        "\n",
        "\n",
        "model_names = [\n",
        "    \"Gaussian SVC\",\n",
        "    \"RandomForestClassifier\",\n",
        "    \"Naive Bayes\",\n",
        "    \"KNeighborsClassifier\",\n",
        "    \"SGDClassifier\",\n",
        "    \"DecisionTreeClassifier\",\n",
        "    \"AdaBoostClassifier\",\n",
        "    \"XGBClassifier\",\n",
        "]"
      ],
      "metadata": {
        "id": "6sCOQgBa5k_Z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Split data into train, validation, and test sets\n",
        "train_val_df, test_df = train_test_split(partition_df, test_size=0.2, random_state=42)\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=0.25, random_state=42) # 0.25 x 0.8 = 0.2\n",
        "\n",
        "# Initialize vectorizers\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "bow_vectorizer = CountVectorizer()\n",
        "\n",
        "# KFold setup\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=69)\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "def train_and_evaluate(vectorizer, model_objs, model_names, train_df, val_df):\n",
        "    results = []\n",
        "\n",
        "    X_train_vect = vectorizer.fit_transform(train_df['Words'])\n",
        "    X_val_vect = vectorizer.transform(val_df['Words'])\n",
        "\n",
        "    X_train_vect_df = pd.DataFrame(X_train_vect.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "    X_val_vect_df = pd.DataFrame(X_val_vect.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "    y_train_onehot = onehot_encoder.fit_transform(train_df[['Label']])\n",
        "    y_val_onehot = onehot_encoder.transform(val_df[['Label']])\n",
        "\n",
        "    y_train_df = pd.DataFrame(y_train_onehot, columns=onehot_encoder.get_feature_names_out(['Label']))\n",
        "    y_val_df = pd.DataFrame(y_val_onehot, columns=onehot_encoder.get_feature_names_out(['Label']))\n",
        "\n",
        "    for model, model_name in zip(model_objs, model_names):\n",
        "        model.fit(X_train_vect_df, y_train_df)\n",
        "        y_val_pred = model.predict(X_val_vect_df)\n",
        "\n",
        "        acc = accuracy_score(y_val_df, y_val_pred)\n",
        "        precision = precision_score(y_val_df, y_val_pred, average='macro')\n",
        "        recall = recall_score(y_val_df, y_val_pred, average='macro')\n",
        "        f1 = f1_score(y_val_df, y_val_pred, average='macro')\n",
        "        roc_auc = roc_auc_score(y_val_df, y_val_pred, average='macro')\n",
        "\n",
        "        results.append({\n",
        "            'Model': model_name,\n",
        "            'Vectorization': vectorizer.__class__.__name__,\n",
        "            'Accuracy': acc,\n",
        "            'Precision': precision,\n",
        "            'Recall': recall,\n",
        "            'F1-Score': f1,\n",
        "            'ROC AUC': roc_auc\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Collect results\n",
        "tfidf_results = train_and_evaluate(tfidf_vectorizer, model_objs, model_names, train_df, val_df)\n",
        "bow_results = train_and_evaluate(bow_vectorizer, model_objs, model_names, train_df, val_df)\n",
        "\n",
        "# Combine results\n",
        "all_results = pd.concat([tfidf_results, bow_results], ignore_index=True)\n",
        "\n",
        "# Save to CSV\n",
        "all_results.to_csv('model_evaluation_results.csv', index=False)\n"
      ],
      "metadata": {
        "id": "mLxnuRRnvLsu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def select_best_model(results_df):\n",
        "    # Selecting the model with the highest F1-Score\n",
        "    best_model = results_df.loc[results_df['F1-Score'].idxmax()]\n",
        "    return best_model\n",
        "\n",
        "# Choose the best model\n",
        "best_model_info = select_best_model(all_results)\n",
        "print(\"Best Model based on F1-Score:\")\n",
        "print(best_model_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnT0ElGIxdHw",
        "outputId": "8c9b81ce-defe-4cff-d517-9c881d379caa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model based on F1-Score:\n",
            "Model            KNeighborsClassifier\n",
            "Vectorization         TfidfVectorizer\n",
            "Accuracy                     0.820833\n",
            "Precision                    0.965322\n",
            "Recall                       0.836079\n",
            "F1-Score                     0.884914\n",
            "ROC AUC                      0.914729\n",
            "Name: 3, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize the test data\n",
        "X_test_vect = vectorizer.transform(test_df['Words'])  # Use the same vectorizer as the champion model (TF-IDF or BoW)\n",
        "X_test_vect_df = pd.DataFrame(X_test_vect.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "# One-hot encoding for test labels\n",
        "y_test_onehot = onehot_encoder.transform(test_df[['Label']])\n",
        "y_test_df = pd.DataFrame(y_test_onehot, columns=onehot_encoder.get_feature_names_out(['Label']))\n",
        "\n",
        "# Make predictions\n",
        "y_test_pred = best_model.predict(X_test_vect_df)\n"
      ],
      "metadata": {
        "id": "nl7_77qm84m4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5mbdcyJelIq",
        "outputId": "5558e1c0-48c5-446b-dc17-dc5dddaf0f3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0]\n",
            " [1 0 0 0 0 0]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0]\n",
            " [0 1 0 0 0 0]\n",
            " [0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 1 0 0]\n",
            " [0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0]\n",
            " [0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0]\n",
            " [1 0 0 0 0 0]\n",
            " [0 0 0 1 0 0]\n",
            " [0 0 1 0 0 0]\n",
            " [1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1]\n",
            " [0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 0 1 0]\n",
            " [1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0]\n",
            " [0 0 0 0 0 1]\n",
            " [1 0 0 0 0 0]\n",
            " [0 1 0 0 0 0]\n",
            " [0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0]\n",
            " [0 0 0 1 0 0]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0]\n",
            " [0 0 0 0 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pwElcLbGbNml",
        "outputId": "8216d7e6-8e1e-434a-854a-bf7aa7cd518b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Label_Charles Dickens  Label_Charlotte Bronte  Label_Edith Wharton  \\\n",
              "0                     0.0                     1.0                  0.0   \n",
              "1                     0.0                     0.0                  1.0   \n",
              "2                     0.0                     0.0                  1.0   \n",
              "3                     0.0                     0.0                  1.0   \n",
              "4                     0.0                     0.0                  0.0   \n",
              "5                     0.0                     0.0                  0.0   \n",
              "6                     0.0                     0.0                  0.0   \n",
              "7                     0.0                     0.0                  1.0   \n",
              "8                     0.0                     0.0                  0.0   \n",
              "9                     0.0                     0.0                  0.0   \n",
              "10                    0.0                     0.0                  1.0   \n",
              "11                    0.0                     0.0                  0.0   \n",
              "12                    1.0                     0.0                  0.0   \n",
              "13                    0.0                     0.0                  1.0   \n",
              "14                    0.0                     0.0                  1.0   \n",
              "15                    0.0                     1.0                  0.0   \n",
              "16                    0.0                     0.0                  1.0   \n",
              "17                    0.0                     0.0                  0.0   \n",
              "18                    0.0                     0.0                  1.0   \n",
              "19                    0.0                     0.0                  0.0   \n",
              "20                    0.0                     0.0                  0.0   \n",
              "21                    0.0                     0.0                  0.0   \n",
              "22                    1.0                     0.0                  0.0   \n",
              "23                    0.0                     0.0                  0.0   \n",
              "24                    0.0                     1.0                  0.0   \n",
              "25                    0.0                     0.0                  0.0   \n",
              "26                    0.0                     0.0                  0.0   \n",
              "27                    0.0                     1.0                  0.0   \n",
              "28                    1.0                     0.0                  0.0   \n",
              "29                    0.0                     0.0                  0.0   \n",
              "30                    1.0                     0.0                  0.0   \n",
              "31                    0.0                     1.0                  0.0   \n",
              "32                    0.0                     0.0                  0.0   \n",
              "33                    1.0                     0.0                  0.0   \n",
              "34                    0.0                     0.0                  0.0   \n",
              "35                    0.0                     0.0                  0.0   \n",
              "36                    0.0                     0.0                  1.0   \n",
              "37                    0.0                     1.0                  0.0   \n",
              "38                    0.0                     0.0                  0.0   \n",
              "39                    0.0                     1.0                  0.0   \n",
              "40                    0.0                     1.0                  0.0   \n",
              "41                    0.0                     0.0                  1.0   \n",
              "42                    0.0                     0.0                  0.0   \n",
              "43                    0.0                     0.0                  0.0   \n",
              "44                    0.0                     0.0                  0.0   \n",
              "45                    0.0                     0.0                  0.0   \n",
              "46                    0.0                     0.0                  0.0   \n",
              "47                    0.0                     0.0                  0.0   \n",
              "48                    0.0                     0.0                  0.0   \n",
              "49                    0.0                     0.0                  0.0   \n",
              "50                    1.0                     0.0                  0.0   \n",
              "51                    0.0                     0.0                  0.0   \n",
              "52                    0.0                     0.0                  1.0   \n",
              "53                    0.0                     0.0                  0.0   \n",
              "54                    0.0                     1.0                  0.0   \n",
              "55                    1.0                     0.0                  0.0   \n",
              "56                    0.0                     0.0                  0.0   \n",
              "57                    0.0                     0.0                  1.0   \n",
              "58                    0.0                     0.0                  0.0   \n",
              "59                    0.0                     0.0                  0.0   \n",
              "\n",
              "    Label_Emily Bronte  Label_George Eliot  Label_Jane Austen  \n",
              "0                  0.0                 0.0                0.0  \n",
              "1                  0.0                 0.0                0.0  \n",
              "2                  0.0                 0.0                0.0  \n",
              "3                  0.0                 0.0                0.0  \n",
              "4                  0.0                 1.0                0.0  \n",
              "5                  0.0                 1.0                0.0  \n",
              "6                  0.0                 1.0                0.0  \n",
              "7                  0.0                 0.0                0.0  \n",
              "8                  0.0                 0.0                1.0  \n",
              "9                  0.0                 0.0                1.0  \n",
              "10                 0.0                 0.0                0.0  \n",
              "11                 1.0                 0.0                0.0  \n",
              "12                 0.0                 0.0                0.0  \n",
              "13                 0.0                 0.0                0.0  \n",
              "14                 0.0                 0.0                0.0  \n",
              "15                 0.0                 0.0                0.0  \n",
              "16                 0.0                 0.0                0.0  \n",
              "17                 1.0                 0.0                0.0  \n",
              "18                 0.0                 0.0                0.0  \n",
              "19                 0.0                 1.0                0.0  \n",
              "20                 0.0                 1.0                0.0  \n",
              "21                 0.0                 1.0                0.0  \n",
              "22                 0.0                 0.0                0.0  \n",
              "23                 0.0                 0.0                1.0  \n",
              "24                 0.0                 0.0                0.0  \n",
              "25                 0.0                 1.0                0.0  \n",
              "26                 0.0                 0.0                1.0  \n",
              "27                 0.0                 0.0                0.0  \n",
              "28                 0.0                 0.0                0.0  \n",
              "29                 1.0                 0.0                0.0  \n",
              "30                 0.0                 0.0                0.0  \n",
              "31                 0.0                 0.0                0.0  \n",
              "32                 1.0                 0.0                0.0  \n",
              "33                 0.0                 0.0                0.0  \n",
              "34                 0.0                 1.0                0.0  \n",
              "35                 1.0                 0.0                0.0  \n",
              "36                 0.0                 0.0                0.0  \n",
              "37                 0.0                 0.0                0.0  \n",
              "38                 0.0                 0.0                1.0  \n",
              "39                 0.0                 0.0                0.0  \n",
              "40                 0.0                 0.0                0.0  \n",
              "41                 0.0                 0.0                0.0  \n",
              "42                 0.0                 0.0                1.0  \n",
              "43                 0.0                 0.0                1.0  \n",
              "44                 0.0                 1.0                0.0  \n",
              "45                 0.0                 1.0                0.0  \n",
              "46                 0.0                 1.0                0.0  \n",
              "47                 0.0                 0.0                1.0  \n",
              "48                 1.0                 0.0                0.0  \n",
              "49                 0.0                 0.0                1.0  \n",
              "50                 0.0                 0.0                0.0  \n",
              "51                 0.0                 1.0                0.0  \n",
              "52                 0.0                 0.0                0.0  \n",
              "53                 0.0                 0.0                1.0  \n",
              "54                 0.0                 0.0                0.0  \n",
              "55                 0.0                 0.0                0.0  \n",
              "56                 0.0                 1.0                0.0  \n",
              "57                 0.0                 0.0                0.0  \n",
              "58                 0.0                 1.0                0.0  \n",
              "59                 0.0                 0.0                1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-80478a28-4e4e-47be-88e1-5ba44ea3a874\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label_Charles Dickens</th>\n",
              "      <th>Label_Charlotte Bronte</th>\n",
              "      <th>Label_Edith Wharton</th>\n",
              "      <th>Label_Emily Bronte</th>\n",
              "      <th>Label_George Eliot</th>\n",
              "      <th>Label_Jane Austen</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80478a28-4e4e-47be-88e1-5ba44ea3a874')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-80478a28-4e4e-47be-88e1-5ba44ea3a874 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-80478a28-4e4e-47be-88e1-5ba44ea3a874');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-89e2883d-4800-441a-8b32-96b03c46fd76\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-89e2883d-4800-441a-8b32-96b03c46fd76')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-89e2883d-4800-441a-8b32-96b03c46fd76 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_3eec46bb-325c-4c29-85b0-565ae4a56cac\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('y_test_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3eec46bb-325c-4c29-85b0-565ae4a56cac button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('y_test_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT"
      ],
      "metadata": {
        "id": "3QW9DHmQJU2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBUu9VzuJ1qQ",
        "outputId": "60d3495c-64e1-4236-a9d7-411b95aadd6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_text\n",
            "  Downloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/5.2 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m4.5/5.2 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (0.16.0)\n",
            "Requirement already satisfied: tensorflow<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.35.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.1.4)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.2.2)\n",
            "Installing collected packages: tensorflow_text\n",
            "Successfully installed tensorflow_text-2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text"
      ],
      "metadata": {
        "id": "avGfSR3YPIPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1'\n",
        "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"
      ],
      "metadata": {
        "id": "8t0dCypmJex7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
      ],
      "metadata": {
        "id": "QRBCF9JwI8be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
      ],
      "metadata": {
        "id": "1O4ncrD6JJz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_test = ['this is such an amazing movie!']\n",
        "text_preprocessed = bert_preprocess_model(text_test)\n",
        "\n",
        "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
        "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
        "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
        "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
        "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awzRkcK6JWjC",
        "outputId": "d0837f41-72c2-4f6f-b545-97c076ce0980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys       : ['input_mask', 'input_word_ids', 'input_type_ids']\n",
            "Shape      : (1, 128)\n",
            "Word Ids   : [ 101 2023 2003 2107 2019 6429 3185  999  102    0    0    0]\n",
            "Input Mask : [1 1 1 1 1 1 1 1 1 0 0 0]\n",
            "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_results = bert_model(text_preprocessed)\n",
        "\n",
        "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
        "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
        "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
        "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
        "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVrP2qRRJOwJ",
        "outputId": "3208421e-740a-43e2-9381-82006b96c12a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1\n",
            "Pooled Outputs Shape:(1, 512)\n",
            "Pooled Outputs Values:[-0.25969836 -0.52364445  0.9036142  -0.55134004 -0.88770914  0.9886292\n",
            " -0.30357572 -0.00745822 -0.9583914   0.06638025  0.23976119  0.06133483]\n",
            "Sequence Outputs Shape:(1, 128, 512)\n",
            "Sequence Outputs Values:[[-0.1338202   0.03000332  0.17117347 ... -0.47139746 -0.92813057\n",
            "   0.51842195]\n",
            " [-0.05726065  1.0102304  -0.164846   ... -0.77384204 -0.5603515\n",
            "   0.07679403]\n",
            " [-1.2910262   0.0331322   0.7465316  ... -0.45870095  0.32357264\n",
            "   0.24169521]\n",
            " ...\n",
            " [ 0.01642712  0.0605648   0.43864334 ...  0.24693727 -0.2777899\n",
            "   0.3536233 ]\n",
            " [-0.3973329   0.0986197   0.16961995 ...  0.16997036 -0.6732824\n",
            "   0.42493147]\n",
            " [ 0.16625747 -0.19789703 -0.4526961  ...  0.31699604 -0.6168943\n",
            "   0.11923101]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_classifier_model():\n",
        "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "  encoder_inputs = preprocessing_layer(text_input)\n",
        "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "  outputs = encoder(encoder_inputs)\n",
        "  net = outputs['pooled_output']\n",
        "  net = tf.keras.layers.Dense(128, activation='relu', name='hidden_1')(net)\n",
        "  net = tf.keras.layers.Dropout(0.3)(net)\n",
        "  net = tf.keras.layers.Dense(6, activation='softmax', name='classifier')(net)\n",
        "  return tf.keras.Model(text_input, net)"
      ],
      "metadata": {
        "id": "L9leNQPjJS-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model = build_classifier_model()\n",
        "bert_raw_result = classifier_model(tf.constant(text_test))\n",
        "print(bert_raw_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4eyTvI-JcsH",
        "outputId": "d6027330-7fb9-4ad7-ed42-09e2229a8f95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0.11506798 0.09176406 0.11182143 0.13499951 0.20483865 0.34150836]], shape=(1, 6), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(classifier_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "Bl2MmOwfMIwQ",
        "outputId": "cc003fa2-0d5a-41b4-d1c5-57408a464189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "metrics = tf.metrics.CategoricalAccuracy()"
      ],
      "metadata": {
        "id": "iEtQxDK2MPob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = partition_df.drop(['Label'], axis=1)\n",
        "y = partition_df['Label']"
      ],
      "metadata": {
        "id": "NHJFuUkWNP3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import warnings\n",
        "import numpy as np\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "y_train_onehot = onehot_encoder.fit_transform(np.array(y_train).reshape(-1,1))\n",
        "y_test_onehot = onehot_encoder.transform(np.array(y_test).reshape(-1,1))\n",
        "\n",
        "y_train_df = pd.DataFrame(y_train_onehot, columns=onehot_encoder.get_feature_names_out(['Label']))\n",
        "y_test_df = pd.DataFrame(y_test_onehot, columns=onehot_encoder.get_feature_names_out(['Label']))"
      ],
      "metadata": {
        "id": "nT50RFWiNXoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ChqYMFCcQD9z",
        "outputId": "12445b00-8a27-4745-d99f-8cb535a7d059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Label_Charles Dickens  Label_Charlotte Bronte  Label_Edith Wharton  \\\n",
              "0                      0.0                     0.0                  0.0   \n",
              "1                      0.0                     1.0                  0.0   \n",
              "2                      0.0                     0.0                  0.0   \n",
              "3                      0.0                     0.0                  0.0   \n",
              "4                      0.0                     0.0                  0.0   \n",
              "..                     ...                     ...                  ...   \n",
              "955                    0.0                     0.0                  1.0   \n",
              "956                    0.0                     0.0                  1.0   \n",
              "957                    0.0                     0.0                  1.0   \n",
              "958                    0.0                     0.0                  0.0   \n",
              "959                    0.0                     0.0                  1.0   \n",
              "\n",
              "     Label_Emily Bronte  Label_George Eliot  Label_Jane Austen  \n",
              "0                   1.0                 0.0                0.0  \n",
              "1                   0.0                 0.0                0.0  \n",
              "2                   0.0                 0.0                1.0  \n",
              "3                   0.0                 1.0                0.0  \n",
              "4                   0.0                 0.0                1.0  \n",
              "..                  ...                 ...                ...  \n",
              "955                 0.0                 0.0                0.0  \n",
              "956                 0.0                 0.0                0.0  \n",
              "957                 0.0                 0.0                0.0  \n",
              "958                 0.0                 1.0                0.0  \n",
              "959                 0.0                 0.0                0.0  \n",
              "\n",
              "[960 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a3414cf1-c017-4b70-aa0e-384db5f595b5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label_Charles Dickens</th>\n",
              "      <th>Label_Charlotte Bronte</th>\n",
              "      <th>Label_Edith Wharton</th>\n",
              "      <th>Label_Emily Bronte</th>\n",
              "      <th>Label_George Eliot</th>\n",
              "      <th>Label_Jane Austen</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>955</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>956</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>957</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>959</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>960 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3414cf1-c017-4b70-aa0e-384db5f595b5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a3414cf1-c017-4b70-aa0e-384db5f595b5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a3414cf1-c017-4b70-aa0e-384db5f595b5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-db451602-fb38-45d1-8bbc-44fc17ca0047\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-db451602-fb38-45d1-8bbc-44fc17ca0047')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-db451602-fb38-45d1-8bbc-44fc17ca0047 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_c5f8f29a-1d59-4436-922d-7d2e6914d337\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('y_train_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c5f8f29a-1d59-4436-922d-7d2e6914d337 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('y_train_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "optimizer = tf.keras.optimizers.Adam(0.0001)"
      ],
      "metadata": {
        "id": "EQCQlwweMjPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model.compile(optimizer=optimizer,\n",
        "                         loss=loss,\n",
        "                         metrics=metrics)"
      ],
      "metadata": {
        "id": "OBiomcltMmFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uzdbEyTVNdw",
        "outputId": "13228ffb-51fa-4bfc-b552-2b7c124fab56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " text (InputLayer)           [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " preprocessing (KerasLayer)  {'input_word_ids': (None,    0         ['text[0][0]']                \n",
            "                             128),                                                                \n",
            "                              'input_mask': (None, 128)                                           \n",
            "                             , 'input_type_ids': (None,                                           \n",
            "                              128)}                                                               \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)   {'pooled_output': (None, 5   2245888   ['preprocessing[0][0]',       \n",
            "                             12),                         1          'preprocessing[0][1]',       \n",
            "                              'encoder_outputs': [(None              'preprocessing[0][2]']       \n",
            "                             , 128, 512),                                                         \n",
            "                              (None, 128, 512)],                                                  \n",
            "                              'default': (None, 512),                                             \n",
            "                              'sequence_output': (None,                                           \n",
            "                              128, 512)}                                                          \n",
            "                                                                                                  \n",
            " hidden_1 (Dense)            (None, 128)                  65664     ['BERT_encoder[0][3]']        \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 128)                  0         ['hidden_1[0][0]']            \n",
            "                                                                                                  \n",
            " classifier (Dense)          (None, 6)                    774       ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 22525319 (85.93 MB)\n",
            "Trainable params: 22525318 (85.93 MB)\n",
            "Non-trainable params: 1 (1.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = classifier_model.fit(X_train,y_train_df, batch_size=128, epochs=epochs, validation_data=(X_test, y_test_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3-KEz34Ny7U",
        "outputId": "7f554c7b-19b5-465e-dd0f-a8a3781e3591"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 19s 1s/step - loss: 0.0058 - categorical_accuracy: 0.9875 - val_loss: 0.4048 - val_categorical_accuracy: 0.9333\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 8s 951ms/step - loss: 0.0057 - categorical_accuracy: 0.9990 - val_loss: 0.3832 - val_categorical_accuracy: 0.9417\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 8s 1s/step - loss: 0.0054 - categorical_accuracy: 0.9990 - val_loss: 0.3831 - val_categorical_accuracy: 0.9333\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 9s 1s/step - loss: 0.0076 - categorical_accuracy: 0.9979 - val_loss: 0.4578 - val_categorical_accuracy: 0.9250\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 9s 1s/step - loss: 0.0045 - categorical_accuracy: 0.9969 - val_loss: 0.3784 - val_categorical_accuracy: 0.9417\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 8s 964ms/step - loss: 0.0029 - categorical_accuracy: 0.9990 - val_loss: 0.3567 - val_categorical_accuracy: 0.9500\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 9s 1s/step - loss: 6.3233e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3566 - val_categorical_accuracy: 0.9375\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 9s 1s/step - loss: 0.0010 - categorical_accuracy: 1.0000 - val_loss: 0.4194 - val_categorical_accuracy: 0.9250\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 8s 969ms/step - loss: 0.0020 - categorical_accuracy: 0.9990 - val_loss: 0.3815 - val_categorical_accuracy: 0.9250\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 8s 1s/step - loss: 2.3897e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3442 - val_categorical_accuracy: 0.9458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "kZ855V5NZNfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = to_categorical(np.argmax(classifier_model.predict(X_test), axis=-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jq6xrMG_Oznt",
        "outputId": "57018494-1f0e-4b05-9231-1c713ac4c5c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 156ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AxmU_-zYOx5",
        "outputId": "35c5ff6e-c184-4202-ea05-519d3f5ee7b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1.],\n",
              "       ...,\n",
              "       [0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = accuracy_score(y_pred, y_test_df)\n",
        "precision = precision_score(y_pred, y_test_onehot, average='macro')\n",
        "recall = recall_score(y_pred, y_test_onehot, average='macro')\n",
        "f1 = f1_score(y_pred, y_test_onehot, average='macro')\n",
        "roc_auc = roc_auc_score(y_test_onehot, y_pred, average='macro')"
      ],
      "metadata": {
        "id": "Iihke22-Xmgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Average Accuracy: {}\".format(acc))\n",
        "print(\"Average Precision: {}\".format(precision))\n",
        "print(\"Average Recall: {}\".format(recall))\n",
        "print(\"Average F1: {}\".format(f1))\n",
        "print(\"Average ROC AUC: {}\".format(roc_auc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krTXYdBWXwvw",
        "outputId": "091a024a-cf6e-42c5-b400-4bf973276771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.9458333333333333\n",
            "Average Precision: 0.9465236274446801\n",
            "Average Recall: 0.9463038848866577\n",
            "Average F1: 0.9460698238758353\n",
            "Average ROC AUC: 0.9678226909254906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model.save('BERT_classifier.h5')"
      ],
      "metadata": {
        "id": "ekY3AWGfZbjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CqS2cns2Z3m_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}